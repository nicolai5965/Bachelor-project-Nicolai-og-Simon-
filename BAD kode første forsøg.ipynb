{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e10272-c099-45b0-bacb-314991c4c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import pandas as pd\n",
    "import os\n",
    "import trackml\n",
    "import time\n",
    "from numba import jit\n",
    "from trackml.dataset import load_event , load_dataset\n",
    "from trackml.score import score_event\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2c9ee-74f4-4e6f-b2fa-910063c60947",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984963d4-ac8d-4205-a631-a79facc59767",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_train_100, cells_train_100, particles_train_100, truth_train_100 = load_event('train_100_events/event000001000')\n",
    "data_detectors = pd.read_csv(r\"detectors.csv\")\n",
    "\n",
    "#print(data_detectors.iloc[:,:1])\n",
    "#print(truth_train_100[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63cd5294-be3f-425b-8d8a-d43ee4cc4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_import_100_sample():\n",
    "    event_id_10 = np.linspace(0,9,10)\n",
    "    event_id_100 = np.linspace(10,99,90)\n",
    "\n",
    "    cells_all = []\n",
    "    hits_all = []\n",
    "    particles_all = []\n",
    "    truth_all = []\n",
    "\n",
    "    for i in range(len(event_id_10)):\n",
    "        cells_all.append(pd.read_csv('train_100_events/event00000100%d-cells.csv' % event_id_10[i]))\n",
    "    for i in range(len(event_id_100)):\n",
    "        cells_all.append(pd.read_csv('train_100_events/event0000010%d-cells.csv' % event_id_100[i]))\n",
    "\n",
    "    for i in range(len(event_id_10)):\n",
    "        hits_all.append(pd.read_csv('train_100_events/event00000100%d-hits.csv' % event_id_10[i]))\n",
    "    for i in range(len(event_id_100)):\n",
    "        hits_all.append(pd.read_csv('train_100_events/event0000010%d-hits.csv' % event_id_100[i]))\n",
    "\n",
    "    for i in range(len(event_id_10)):\n",
    "        particles_all.append(pd.read_csv('train_100_events/event00000100%d-particles.csv' % event_id_10[i]))\n",
    "    for i in range(len(event_id_100)):\n",
    "        particles_all.append(pd.read_csv('train_100_events/event0000010%d-particles.csv' % event_id_100[i]))\n",
    "\n",
    "    for i in range(len(event_id_10)):\n",
    "        truth_all.append(pd.read_csv('train_100_events/event00000100%d-truth.csv' % event_id_10[i]))\n",
    "    for i in range(len(event_id_100)):\n",
    "        truth_all.append(pd.read_csv('train_100_events/event0000010%d-truth.csv' % event_id_100[i]))\n",
    "    return cells_all , hits_all , particles_all , truth_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc52b53b-3bfa-4242-8bcb-f752d7eb3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# cells_all = func_import_100_sample()[0]\n",
    "# hits_all = func_import_100_sample()[1]\n",
    "# particles_all = func_import_100_sample()[2]\n",
    "# truth_all = func_import_100_sample()[3]\n",
    "\n",
    "# end = time.time()\n",
    "# run_time = end - start\n",
    "# print(run_time, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c44f6-5bc1-4703-94b1-62f0e80608cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Making functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0131157-a031-43c2-9016-6db59254d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 120901\n",
      "206 120926\n",
      "206 120926\n",
      "No, truth[hit_id] does not contains all elements in hits[hit_id]\n",
      "No, hits[hit_id] does not contains all elements in truth[hit_id]\n",
      "      hit_id           x           y       z  volume_id  layer_id  module_id\n",
      "0        206 -118.573997 -122.498001 -1502.0          7         2         15\n",
      "1        498   72.551003  -94.188499 -1498.0          7         2         38\n",
      "2        532   72.722801  -94.425003 -1502.0          7         2         40\n",
      "3        552   44.314999  -28.215500 -1497.5          7         2         42\n",
      "4        579   44.448200  -28.322701 -1502.5          7         2         44\n",
      "...      ...         ...         ...     ...        ...       ...        ...\n",
      "9393  120854 -477.261993  812.588989  2952.5         18        12         82\n",
      "9394  120894 -645.659973  393.026001  2944.5         18        12         89\n",
      "9395  120901 -772.278992  353.083008  2947.5         18        12         91\n",
      "9396  120907 -755.176025  364.250000  2947.5         18        12         91\n",
      "9397  120926 -800.447021  193.416000  2947.5         18        12         95\n",
      "\n",
      "[9398 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def func_cleaning_data(cells , hits, particles , truth):\n",
    "    #Finding all hit_id that is noice, to use in other files for removing nocie in them.\n",
    "    def noice(truth):\n",
    "        truth_hit_id_noice = [truth.hit_id[i] for i in range(len(truth)) if truth.particle_id[i] == 0]\n",
    "        return truth_hit_id_noice\n",
    "    truth_hit_id_noice_list = noice(truth)\n",
    "    #Removing all the noice in the truth file:\n",
    "    truth_zero_noice = truth.drop(truth.index[truth['particle_id'] == 0]).reset_index()\n",
    "    #Removing all the data where the nhits is >=3 :\n",
    "    particles_zero_noice = particles.drop(particles.index[particles['nhits'] <= 3]).reset_index()\n",
    "    \n",
    "  \n",
    "\n",
    "    #Making a function that can remove all the hit_id that was seen as noice in the truth fil. Used in the hits and cells files.\n",
    "    def FRBV(file_name, column_name, list_of_values): # filter a row by a value or a list of values\n",
    "        return file_name[~file_name[column_name].isin(list_of_values)]\n",
    "    #Making a function that can make a list of the hit_ids that has a weight of 0.\n",
    "    def weight_equle_0(data):\n",
    "        data = [data.hit_id[i] for i in range(len(data)) if data.weight[i] == 0]\n",
    "        return data\n",
    "    \n",
    "    def weight_equle_02(data):\n",
    "        data = [data.hit_id[i] for i in range(len(data)) if data.weight[i] != 0]\n",
    "        return data\n",
    "    \n",
    "    #Removing all the noice in the cells file:\n",
    "    cells_zero_noice = FRBV(cells , \"hit_id\" , truth_hit_id_noice_list).reset_index()\n",
    "    #Removing all the noice in the hits file:\n",
    "    hits_zero_noice = FRBV(hits , \"hit_id\" , truth_hit_id_noice_list).reset_index()\n",
    "    \n",
    "    #Sorts the truth and particle data\n",
    "    truth_zero_noice_sorted = truth_zero_noice.sort_values(by = \"particle_id\",ascending=True)\n",
    "    truth_zero_noice_sorted_unique = np.unique(truth_zero_noice_sorted.particle_id)\n",
    "    particles_zero_noice_sorted_unique = particles_zero_noice.sort_values(by = \"particle_id\",ascending=True)\n",
    "    \n",
    "    #Removes all the data in particle file, where there is no nhits = 0,  that has a nhits over 7.\n",
    "    def nhit_over_7(data):\n",
    "        data = [data.particle_id[i] for i in range(len(data)) if data.nhits[i] > 7]\n",
    "        return data\n",
    "    #Removing all the data where nhits is less then 7\n",
    "    particle_id_with_nhits_over_7 = nhit_over_7(particles_zero_noice_sorted_unique)\n",
    "    \n",
    "    #Removing all the data where nhits is over then 7\n",
    "    particle_id_with_nhits_lees_7 = FRBV(particles_zero_noice_sorted_unique , \"particle_id\" , particle_id_with_nhits_over_7).drop(\"index\",axis = 1).reset_index().drop(\"index\",axis = 1)\n",
    "    \n",
    "    #Removing all the data where a particle_id has more then 7 nhits.\n",
    "    truth_zero_noice_sorted_with_nhits_lees_7 = FRBV(truth_zero_noice_sorted , \"particle_id\" , particle_id_with_nhits_over_7).drop(\"index\",axis = 1).reset_index().drop(\"index\",axis = 1)\n",
    "    \n",
    "    truth_weight_0_list = weight_equle_0(truth_zero_noice_sorted_with_nhits_lees_7)\n",
    "    \n",
    "    truth_zero_noice_sorted_with_nhits_lees_7_weight_0 = FRBV(truth_zero_noice_sorted_with_nhits_lees_7,\"hit_id\",truth_weight_0_list).reset_index().drop(\"index\",axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Removing the data where the particle_id has less then 7 nhits.\n",
    "    truth_zero_noice_sorted_with_nhits_over_7 = FRBV(truth_zero_noice_sorted , \"particle_id\" ,truth_zero_noice_sorted_with_nhits_lees_7_weight_0.particle_id).drop(\"index\",axis = 1).reset_index().drop(\"index\",axis = 1)\n",
    "    \n",
    "    truth_weight_0_list_over = weight_equle_02(truth_zero_noice_sorted_with_nhits_over_7)\n",
    "    \n",
    "    truth_zero_noice_sorted_with_nhits_over_7_weight_0 = FRBV(truth_zero_noice_sorted_with_nhits_over_7,\"hit_id\",truth_weight_0_list_over).reset_index().drop(\"index\",axis = 1)\n",
    "    truth_zero_noice_sorted_with_nhits_over_7_weight_0 = FRBV(truth_zero_noice_sorted_with_nhits_over_7,\"hit_id\",truth_weight_0_list).reset_index().drop(\"index\",axis = 1)\n",
    "    \n",
    "    \n",
    "    #Removing the data where the hit_id has less the 7 nhits.\n",
    "    hits_zero_noice_sorted_with_nhits_lees_7 = FRBV(hits_zero_noice, \"hit_id\",truth_zero_noice_sorted_with_nhits_over_7_weight_0[\"hit_id\"]).drop(\"index\",axis = 1).reset_index().drop(\"index\",axis = 1)\n",
    "    #Removing the data where the hit_id has less the 7 nhits.\n",
    "    cells_zero_noice_sorted_with_nhits_lees_7 = FRBV(cells_zero_noice, \"hit_id\",truth_zero_noice_sorted_with_nhits_over_7_weight_0[\"hit_id\"]).drop(\"index\",axis = 1).reset_index().drop(\"index\",axis = 1)\n",
    "    \n",
    "    return cells_zero_noice_sorted_with_nhits_lees_7 , hits_zero_noice_sorted_with_nhits_lees_7 ,particle_id_with_nhits_lees_7 , truth_zero_noice_sorted_with_nhits_lees_7_weight_0, truth_zero_noice_sorted_with_nhits_over_7_weight_0\n",
    "    \n",
    "\n",
    "    \n",
    "cells , hits , particles, truth , truth2 = func_cleaning_data(cells_train_100,hits_train_100,particles_train_100,truth_train_100)\n",
    "\n",
    "print(min(truth[\"hit_id\"]),max(truth[\"hit_id\"])) \n",
    "print(min(hits[\"hit_id\"]),max(hits[\"hit_id\"])) \n",
    "print(min(cells[\"hit_id\"]),max(cells[\"hit_id\"]))\n",
    "\n",
    "result =  all(elem in truth[\"hit_id\"]  for elem in hits[\"hit_id\"])\n",
    "if result:\n",
    "    print(\"Yes, truth[hit_id] contains all elements in hits[hit_id]\")    \n",
    "else :\n",
    "    print(\"No, truth[hit_id] does not contains all elements in hits[hit_id]\")\n",
    "    \n",
    "    \n",
    "result =  all(elem in hits[\"hit_id\"]  for elem in truth[\"hit_id\"])\n",
    "if result:\n",
    "    print(\"Yes, hits[hit_id] contains all elements in truth[hit_id]\")    \n",
    "else :\n",
    "    print(\"No, hits[hit_id] does not contains all elements in truth[hit_id]\")\n",
    "\n",
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f88dee-6a17-4cef-b8e8-3621b9e88046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8b963ee-d989-4fb3-9f7b-1f55b5554c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calling data cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5134fe4f-28e2-4d71-baf7-92b16c15e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of particle_id_with_nhits_lees_7  1323\n",
      "Lenght of truth_zero_noice_sorted_with_nhits_lees_7  7265\n",
      "Lenght of hits_zero_noice_sorted_with_nhits_lees_7  9398\n",
      "Lenght of cellszero_noice_sorted_with_nhits_lees_7  83081\n",
      "4 7\n",
      "4 7\n",
      "8 19\n",
      "206 120901\n",
      "206 120926\n",
      "206 120926\n",
      "T2 2 120939\n",
      "2.068413734436035 s\n"
     ]
    }
   ],
   "source": [
    "Start = time.time()\n",
    "\n",
    "cells , hits , particles, truth , truth2 = func_cleaning_data(cells_train_100,hits_train_100,particles_train_100,truth_train_100)\n",
    "\n",
    "print(\"Lenght of particle_id_with_nhits_lees_7 \" ,len(particles))\n",
    "print(\"Lenght of truth_zero_noice_sorted_with_nhits_lees_7 \" , len(truth))\n",
    "#print(\"Lenght of truth_zero_noice_sorted_with_nhits_over_7 \" , len(truth2[\"hit_id\"]))\n",
    "print(\"Lenght of hits_zero_noice_sorted_with_nhits_lees_7 \" ,len(hits))\n",
    "print(\"Lenght of cellszero_noice_sorted_with_nhits_lees_7 \" ,len(cells))\n",
    "\n",
    "#print(truth[\"particle_id\"].value_counts())\n",
    "# print(hits[\"hit_id\"].value_counts())\n",
    "# print(cells[\"hit_id\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "print(min(truth[\"particle_id\"].value_counts()),max(truth[\"particle_id\"].value_counts())) \n",
    "print(min(particles.nhits),max(particles.nhits)) \n",
    "print(min(truth2[\"particle_id\"].value_counts()),max(truth2[\"particle_id\"].value_counts())) \n",
    "\n",
    "print(min(truth[\"hit_id\"]),max(truth[\"hit_id\"])) \n",
    "print(min(hits[\"hit_id\"]),max(hits[\"hit_id\"])) \n",
    "print(min(cells[\"hit_id\"]),max(cells[\"hit_id\"]))\n",
    "print(\"T2\",min(truth2[\"hit_id\"]),max(truth2[\"hit_id\"])) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "run_time = end - Start\n",
    "print(run_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b73f5c8d-f4c7-4e04-8eac-8828b558a100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 120939\n",
      "2 120939\n",
      "0          206\n",
      "1          498\n",
      "2          532\n",
      "3          552\n",
      "4          579\n",
      "         ...  \n",
      "9393    120854\n",
      "9394    120894\n",
      "9395    120901\n",
      "9396    120907\n",
      "9397    120926\n",
      "Name: hit_id, Length: 9398, dtype: int32\n",
      "0          206\n",
      "1          498\n",
      "2          532\n",
      "3          552\n",
      "4          579\n",
      "         ...  \n",
      "9393    120854\n",
      "9394    120894\n",
      "9395    120901\n",
      "9396    120907\n",
      "9397    120926\n",
      "Name: hit_id, Length: 9398, dtype: int32\n",
      "0          206\n",
      "1          498\n",
      "2          532\n",
      "3          552\n",
      "4          579\n",
      "         ...  \n",
      "9393    120854\n",
      "9394    120894\n",
      "9395    120901\n",
      "9396    120907\n",
      "9397    120926\n",
      "Name: hit_id, Length: 9398, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "def FRBV(file_name, column_name, list_of_values): # filter a row by a value or a list of values\n",
    "    return file_name[~file_name[column_name].isin(list_of_values)]\n",
    "def weight_equle_0(data):\n",
    "    data = [data.hit_id[i] for i in range(len(data)) if data.weight[i] == 0]\n",
    "    return data\n",
    "\n",
    "asd = weight_equle_0(truth)\n",
    "dsa = FRBV(truth,\"hit_id\",asd)\n",
    "\n",
    "tyu = sorted(truth2.hit_id)\n",
    "\n",
    "qwe = FRBV(hits,\"hit_id\",tyu)\n",
    "\n",
    "df = hits[hits.hit_id.isin(tyu) == False]\n",
    "\n",
    "#print(tyu)\n",
    "\n",
    "print(min(tyu),max(tyu))\n",
    "\n",
    "print(min(truth2[\"hit_id\"]),max(truth2[\"hit_id\"])) \n",
    "print(hits.hit_id)\n",
    "print(qwe.hit_id)\n",
    "print(df.hit_id)\n",
    "# print(len(truth))\n",
    "# print(len(asd))\n",
    "# print(dsa[\"weight\"])\n",
    "# print(min(dsa[\"weight\"]),max(dsa[\"weight\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e5cee-3faf-4212-943f-182c4ca332e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Start = time.time()\n",
    "\n",
    "#for i in range(100):\n",
    "#    cells_all_clean , hits_all_clean , particles_all_clean, truth_all_clean  = func_cleaning_data(cells_all[i],hits_all[i],particles_all[i],truth_all[i])\n",
    "\n",
    "end = time.time()\n",
    "run_time = end - Start\n",
    "print(run_time, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d9741-08a0-4073-a6a7-809c51b4d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "Start = time.time()\n",
    "\n",
    "def car_to_cyl_cood(x,y,z):\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y,x)\n",
    "    z = z\n",
    "    return r , phi , z \n",
    "\n",
    "\n",
    "car_to_cyl_cood(hits.x,hits.y,hits.z)\n",
    "\n",
    "r_hits , phi_hits , z_hits = car_to_cyl_cood(hits.x,hits.y,hits.z)\n",
    "r_truth , phi_truth , z_truth = car_to_cyl_cood(truth.tx,truth.ty,truth.tz)\n",
    "\n",
    "\n",
    "print(truth.sort_values(by = \"hit_id\",ascending=True).tx)\n",
    "print(hits.sort_values(by = \"hit_id\",ascending=True).x)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "run_time = end - Start\n",
    "print(run_time, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4defc32d-e430-4843-a39a-f05dfadf3296",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Kigger på data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be89cb-e1b8-435a-904e-b284a3a6c6e4",
   "metadata": {},
   "source": [
    "### Ploting data pre GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f32cb3-997e-487c-a41a-ee1b4ec24519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_data(data_rough,data_clean):\n",
    "    XYZ_rough = [[],[],[]]\n",
    "    XYZ_clean = [[],[],[]]\n",
    "    for i, idx in enumerate(range(len(data_rough.x))):\n",
    "        if abs(data_rough.z[i]) < 2000:\n",
    "            XYZ_rough[0].append((data_rough.x[idx]))\n",
    "            XYZ_rough[1].append((data_rough.y[idx]))\n",
    "            XYZ_rough[2].append((data_rough.z[idx]))\n",
    "    print(len(XYZ_rough[0]), len(XYZ_rough[1]), len(XYZ_rough[2]))\n",
    "\n",
    "    for i, idx in enumerate(range(len(data_clean.x))):\n",
    "        if abs(data_clean.z[i]) < 2000:\n",
    "            XYZ_clean[0].append((data_clean.x[idx]))\n",
    "            XYZ_clean[1].append((data_clean.y[idx]))\n",
    "            XYZ_clean[2].append((data_clean.z[idx]))\n",
    "    print(len(XYZ_clean[0]), len(XYZ_clean[1]), len(XYZ_clean[2]))\n",
    "    return XYZ_rough , XYZ_clean\n",
    "\n",
    "XYZ_rough , XYZ_clean = plotting_data(hits_train_100,hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1cdaa-000c-452a-b21d-1068074182c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = 2000\n",
    "figsize = 5\n",
    "alpha = 0.35\n",
    "\n",
    "fig = plt.figure(1, figsize = (figsize,figsize))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(XYZ_rough[0],XYZ_rough[1],XYZ_rough[2], c = XYZ_rough[0], alpha = alpha)\n",
    "plt.xlim(-zoom,zoom)\n",
    "plt.ylim(-zoom,zoom)\n",
    "ax.set_zlim(-zoom,zoom)\n",
    "\n",
    "\n",
    "fig = plt.figure(2, figsize = (figsize,figsize))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(XYZ_clean[0],XYZ_clean[1],XYZ_clean[2], c = XYZ_clean[0] , alpha = alpha)\n",
    "plt.xlim(-zoom,zoom)\n",
    "plt.ylim(-zoom,zoom)\n",
    "ax.set_zlim(-zoom,zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd614f8-eda5-4e42-9339-3d13709120ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.pie(particles.groupby('q')['vx'].count(), labels=['negative', 'positive'],autopct='%.0f%%',shadow=True, radius=1,textprops=dict(color=\"w\"))\n",
    "plt.title('Distribution of particle charges:',color = \"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543df60-0906-49be-bb89-c81c054a89db",
   "metadata": {},
   "source": [
    "### Looking at the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a23d2-70e8-4ddc-9d4a-39ff218c2814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_detectors.cx\n",
    "y = data_detectors.cy\n",
    "z = data_detectors.cz\n",
    "fig = plt.figure(5, figsize = (10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(z , y ,x, c = y, alpha = 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
